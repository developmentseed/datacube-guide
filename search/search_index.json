{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>The datacube worst practices guidebook is intended as an open, community-maintained resource that communicates what not to do when building and using multi-dimensional data products.</p>"},{"location":"#datacube-production-gotchas","title":"Datacube production gotchas","text":"<ul> <li> <p>Tiny data chunks</p> <p> Tiny data chunks</p> </li> <li> <p>Massive data chunks</p> <p> Massive data chunks</p> </li> <li> <p>Tiny coordinate chunks</p> <p> Tiny coordinate chunks</p> </li> <li> <p>Dispersed metadata</p> <p> Dispersed metadata</p> </li> <li> <p>Non-standardized metadata</p> <p> Non-standardized metadata</p> </li> <li> <p>Bloated datatypes</p> <p> Bloated datatypes</p> </li> </ul>"},{"location":"#datacube-usage-gotchas","title":"Datacube usage gotchas","text":"<ul> <li> <p>Default FSSpec Caching</p> <p> Default FSSpec Caching</p> </li> <li> <p>Default GDAL Config</p> <p> Default GDAL Config</p> </li> <li> <p>Default Xarray combine arguments</p> <p> Default Xarray combine arguments</p> </li> <li> <p>Using old libraries</p> <p> Using old libraries</p> </li> </ul>"},{"location":"bloated-datatypes/","title":"Bloated datatypes","text":""},{"location":"bloated-datatypes/#bloated-datatypes","title":"Bloated datatypes\u00b6","text":"<p>There are multiple reasons to avoid larger datatypes than necessary:</p> <ul> <li>Increased storage costs associated with storing more data than necessary.</li> <li>Slower performance and more egress costs than necessary due to more data transfer over the wire than necessary.</li> <li>Can introduce unnecessary numerical rounding issues if using floats where integer representations are sufficient.</li> </ul>"},{"location":"dispersed-metadata/","title":"Dispersed metadata","text":"In\u00a0[1]: Copied! <pre>import datacube_benchmark\nimport zarr\nimport pandas as pd\nimport hvplot.pandas  # noqa\nimport warnings\n\nfrom azure.identity import DefaultAzureCredential\nfrom obstore.auth.azure import AzureCredentialProvider\n</pre> import datacube_benchmark import zarr import pandas as pd import hvplot.pandas  # noqa import warnings  from azure.identity import DefaultAzureCredential from obstore.auth.azure import AzureCredentialProvider In\u00a0[2]: Copied! <pre>config = datacube_benchmark.Config\nconfig.target_array_size = \"50 megabyte\"\nconfig.credential_provider = AzureCredentialProvider(\n    credential=DefaultAzureCredential()\n)\nconfig.warmup_samples = 1\nconfig.create_data = True\n</pre> config = datacube_benchmark.Config config.target_array_size = \"50 megabyte\" config.credential_provider = AzureCredentialProvider(     credential=DefaultAzureCredential() ) config.warmup_samples = 1 config.create_data = True In\u00a0[3]: Copied! <pre>zarr.config.set({\"async.concurrency\": config.zarr_concurrency})\n</pre> zarr.config.set({\"async.concurrency\": config.zarr_concurrency}) Out[3]: <pre>&lt;donfig.config_obj.ConfigSet at 0x7aa999b3c2d0&gt;</pre> <p>Create (or reuse) a blosc compressed array with consolidated metadata</p> In\u00a0[4]: Copied! <pre>url_for_consolidated_metadata = \"https://datacubeguide.blob.core.windows.net/performance-testing/consolidated-metadata.zarr\"\nconsolidated_store = datacube_benchmark.create_or_open_zarr_store(\n    url_for_consolidated_metadata,\n    target_chunk_size=\"25 megabyte\",\n    config=config,\n    consolidated_metadata=True,\n)\n</pre> url_for_consolidated_metadata = \"https://datacubeguide.blob.core.windows.net/performance-testing/consolidated-metadata.zarr\" consolidated_store = datacube_benchmark.create_or_open_zarr_store(     url_for_consolidated_metadata,     target_chunk_size=\"25 megabyte\",     config=config,     consolidated_metadata=True, ) <p>Create (or reuse) a blosc compressed array without consolidated metadata</p> In\u00a0[5]: Copied! <pre>url_for_unconsolidated_metadata = \"https://datacubeguide.blob.core.windows.net/performance-testing/unconsolidated-metadata.zarr\"\nunconsolidated_store = datacube_benchmark.create_or_open_zarr_store(\n    url_for_unconsolidated_metadata,\n    target_chunk_size=\"25 megabyte\",\n    config=config,\n    consolidated_metadata=False,\n)\n</pre> url_for_unconsolidated_metadata = \"https://datacubeguide.blob.core.windows.net/performance-testing/unconsolidated-metadata.zarr\" unconsolidated_store = datacube_benchmark.create_or_open_zarr_store(     url_for_unconsolidated_metadata,     target_chunk_size=\"25 megabyte\",     config=config,     consolidated_metadata=False, ) <p>Add extra arrays since consolidated metadata is more impactful for datacubes with multiple arrays</p> In\u00a0[6]: Copied! <pre>arr = zarr.open_array(consolidated_store, path=\"data\")\nshape = arr.shape\nchunks = arr.chunks\ndtype = arr.dtype\ndimension_names = arr.metadata.dimension_names\nn_extra_arrays = 50\nfor store in [consolidated_store, unconsolidated_store]:\n    for n in range(n_extra_arrays):\n        arr = zarr.create_array(\n            store=store,\n            name=f\"data_{n}\",\n            shape=shape,\n            chunks=chunks,\n            dtype=dtype,\n            dimension_names=dimension_names,\n        )\n        arr[:] = 42\n</pre> arr = zarr.open_array(consolidated_store, path=\"data\") shape = arr.shape chunks = arr.chunks dtype = arr.dtype dimension_names = arr.metadata.dimension_names n_extra_arrays = 50 for store in [consolidated_store, unconsolidated_store]:     for n in range(n_extra_arrays):         arr = zarr.create_array(             store=store,             name=f\"data_{n}\",             shape=shape,             chunks=chunks,             dtype=dtype,             dimension_names=dimension_names,         )         arr[:] = 42 <p>Reconsolidate the metadata in the consolidated store</p> In\u00a0[7]: Copied! <pre>zarr.consolidate_metadata(consolidated_store)\n</pre> zarr.consolidate_metadata(consolidated_store) Out[7]: <pre>&lt;Group object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/consolidated-metadata.zarr\")&gt;</pre> <p>Test time required to open the Zarr store using Xarray</p> In\u00a0[8]: Copied! <pre>warnings.filterwarnings(\n    \"ignore\",\n    message=\"Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata\",\n    category=RuntimeWarning,\n)\nunconsolidated_results = datacube_benchmark.benchmark_dataset_open(\n    unconsolidated_store,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n)\nconsolidated_results = datacube_benchmark.benchmark_dataset_open(\n    consolidated_store,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n)\n</pre> warnings.filterwarnings(     \"ignore\",     message=\"Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata\",     category=RuntimeWarning, ) unconsolidated_results = datacube_benchmark.benchmark_dataset_open(     unconsolidated_store,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ) consolidated_results = datacube_benchmark.benchmark_dataset_open(     consolidated_store,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ) In\u00a0[9]: Copied! <pre>df = pd.concat([consolidated_results.T, unconsolidated_results.T])\ndf[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1)\ndf[\"zarr_store\"] = df[\"zarr_store\"].replace(\n    {\n        'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/unconsolidated-metadata.zarr\")': \"Unconsolidated\",\n        'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/consolidated-metadata.zarr\")': \"Consolidated\",\n    }\n)\n</pre> df = pd.concat([consolidated_results.T, unconsolidated_results.T]) df[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1) df[\"zarr_store\"] = df[\"zarr_store\"].replace(     {         'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/unconsolidated-metadata.zarr\")': \"Unconsolidated\",         'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/consolidated-metadata.zarr\")': \"Consolidated\",     } ) In\u00a0[10]: Copied! <pre>title = \"Duration to open dataset using Xarray\"\nplt = df.hvplot.bar(\n    x=\"zarr_store\",\n    y=\"mean_time\",\n    width=1000,\n    rot=45,\n    title=title,\n    ylabel=\"Duration (s)\",\n    xlabel=\"Metadata structure\",\n)\n</pre> title = \"Duration to open dataset using Xarray\" plt = df.hvplot.bar(     x=\"zarr_store\",     y=\"mean_time\",     width=1000,     rot=45,     title=title,     ylabel=\"Duration (s)\",     xlabel=\"Metadata structure\", ) In\u00a0[11]: Copied! <pre>plt\n</pre> plt Out[11]: <p>The placement of metadata in a single location greatly reduces the time required to load the data.</p>"},{"location":"dispersed-metadata/#dispersed-metadata","title":"Dispersed metadata\u00b6","text":"<p>The primary reason to avoid dispersing metadata throughout a file or across many files is that it increases the number of requests and/or size of requests required for an application to open the file and understand its contents, which slows performance and increases costs.</p> <p>The cloud native geospatial formats guide provides more details about how metadata is organized in different file formats.</p>"},{"location":"dispersed-metadata/#demonstrating-performance-inefficiencies-of-dispersed-metadata","title":"Demonstrating performance inefficiencies of dispersed metadata\u00b6","text":""},{"location":"fsspec-caching-defaults/","title":"Default FSSpec caching arguments","text":"<p>FSSpec's default caching behavior is designed for tabular data and performs poorly for datacubes. Recommendations for better better arguments can be found in the Xarray's tutorial.</p>"},{"location":"gdal-defaults/","title":"Default GDAL Config","text":"<p>Many of GDAL's default configuration settings are designed for local access patterns and perform poorly for data in cloud object storage. Titiler's documentation includes details on some configuration settings that you would likely want to fine-tune. GDAL's documentation includes a full description of all configuration options.</p>"},{"location":"massive-chunks/","title":"Massive data chunks","text":"In\u00a0[1]: Copied! <pre>import datacube_benchmark\nimport zarr\nimport pandas as pd\nimport hvplot.pandas  # noqa\n\nfrom azure.identity import DefaultAzureCredential\nfrom obstore.auth.azure import AzureCredentialProvider\n</pre> import datacube_benchmark import zarr import pandas as pd import hvplot.pandas  # noqa  from azure.identity import DefaultAzureCredential from obstore.auth.azure import AzureCredentialProvider <p>Set constants to use when comparing datacubes</p> In\u00a0[2]: Copied! <pre>config = datacube_benchmark.Config\nconfig.target_array_size = \"1 GB\"\nconfig.credential_provider = AzureCredentialProvider(\n    credential=DefaultAzureCredential()\n)\nconfig.warmup_samples = 1\nconfig.create_data = False\n</pre> config = datacube_benchmark.Config config.target_array_size = \"1 GB\" config.credential_provider = AzureCredentialProvider(     credential=DefaultAzureCredential() ) config.warmup_samples = 1 config.create_data = False In\u00a0[3]: Copied! <pre>zarr.config.set({\"async.concurrency\": config.zarr_concurrency})\n</pre> zarr.config.set({\"async.concurrency\": config.zarr_concurrency}) Out[3]: <pre>&lt;donfig.config_obj.ConfigSet at 0x739745abc550&gt;</pre> <p>Create (or reuse) a blosc compressed array with 25 MB chunks</p> In\u00a0[4]: Copied! <pre>url_for_reg_chunks = (\n    \"https://datacubeguide.blob.core.windows.net/performance-testing/reg-chunks.zarr\"\n)\nreg_chunk_arr = datacube_benchmark.create_or_open_zarr_array(\n    url_for_reg_chunks, target_chunk_size=\"25 megabyte\", config=config\n)\n</pre> url_for_reg_chunks = (     \"https://datacubeguide.blob.core.windows.net/performance-testing/reg-chunks.zarr\" ) reg_chunk_arr = datacube_benchmark.create_or_open_zarr_array(     url_for_reg_chunks, target_chunk_size=\"25 megabyte\", config=config ) <p>Create (or reuse) a blosc compressed array with 1 GB chunks</p> In\u00a0[5]: Copied! <pre>url_for_massive_chunks = \"https://datacubeguide.blob.core.windows.net/performance-testing/massive-chunks.zarr\"\nmassive_chunk_arr = datacube_benchmark.create_or_open_zarr_array(\n    url_for_massive_chunks, target_chunk_size=\"1 GB\", config=config\n)\n</pre> url_for_massive_chunks = \"https://datacubeguide.blob.core.windows.net/performance-testing/massive-chunks.zarr\" massive_chunk_arr = datacube_benchmark.create_or_open_zarr_array(     url_for_massive_chunks, target_chunk_size=\"1 GB\", config=config ) <p>Test the time required to load a random point, a time series, or a spatial slice for the array.</p> In\u00a0[6]: Copied! <pre>massive_chunk_results = datacube_benchmark.benchmark_access_patterns(\n    massive_chunk_arr,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n).reset_index(drop=True)\nreg_chunks_results = datacube_benchmark.benchmark_access_patterns(\n    reg_chunk_arr,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n).reset_index(drop=True)\n</pre> massive_chunk_results = datacube_benchmark.benchmark_access_patterns(     massive_chunk_arr,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ).reset_index(drop=True) reg_chunks_results = datacube_benchmark.benchmark_access_patterns(     reg_chunk_arr,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ).reset_index(drop=True) In\u00a0[7]: Copied! <pre>df = pd.concat([massive_chunk_results, reg_chunks_results])\ndf[\"access_pattern\"] = df[\"access_pattern\"].replace(\n    {\n        \"point\": \"Random point\",\n        \"time_series\": \"Time series\",\n        \"spatial_slice\": \"Spatial slice\",\n        \"full\": \"Full scan\",\n    }\n)\ndf[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1)\ndf[\"chunk_size\"] = df.apply(\n    lambda row: f\"{row['chunk_size'].to(\"MB\").magnitude:,.2f} (MB)\", axis=1\n)\ndf\n</pre> df = pd.concat([massive_chunk_results, reg_chunks_results]) df[\"access_pattern\"] = df[\"access_pattern\"].replace(     {         \"point\": \"Random point\",         \"time_series\": \"Time series\",         \"spatial_slice\": \"Spatial slice\",         \"full\": \"Full scan\",     } ) df[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1) df[\"chunk_size\"] = df.apply(     lambda row: f\"{row['chunk_size'].to(\"MB\").magnitude:,.2f} (MB)\", axis=1 ) df Out[7]: mean_time median_time std_time min_time max_time total_samples access_pattern array_shape chunk_shape chunk_size nchunks shard_shape array_dtype array_size_memory array_size_storage array_compressors compression_ratio zarr_concurrency 0 0.586832 0.5868318689999796 second 0.0 second 0.5868318689999796 second 0.5868318689999796 second 1 Random point (965, 360, 720) (630, 360, 630) 571.54 (MB) 4 None float32 1.000512 gigabyte 0.02831126 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 35.34:1 128 1 0.444508 0.4445084300000417 second 0.0 second 0.4445084300000417 second 0.4445084300000417 second 1 Time series (965, 360, 720) (630, 360, 630) 571.54 (MB) 4 None float32 1.000512 gigabyte 0.02831126 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 35.34:1 128 2 0.492603 0.49260268600005475 second 0.0 second 0.49260268600005475 second 0.49260268600005475 second 1 Spatial slice (965, 360, 720) (630, 360, 630) 571.54 (MB) 4 None float32 1.000512 gigabyte 0.02831126 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 35.34:1 128 3 1.017236 1.0172359650000544 second 0.0 second 1.0172359650000544 second 1.0172359650000544 second 1 Full scan (965, 360, 720) (630, 360, 630) 571.54 (MB) 4 None float32 1.000512 gigabyte 0.02831126 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 35.34:1 128 0 0.027823 0.027823419000014837 second 0.0 second 0.027823419000014837 second 0.027823419000014837 second 1 Random point (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 1 0.072818 0.07281813499980672 second 0.0 second 0.07281813499980672 second 0.07281813499980672 second 1 Time series (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 2 0.052765 0.05276520500001425 second 0.0 second 0.05276520500001425 second 0.05276520500001425 second 1 Spatial slice (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 3 0.921520 0.921520467000164 second 0.0 second 0.921520467000164 second 0.921520467000164 second 1 Full scan (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 In\u00a0[8]: Copied! <pre>title = \"Duration to load data for difference access patterns\"\nplt = df.hvplot.bar(\n    x=\"chunk_size\",\n    y=\"mean_time\",\n    by=\"access_pattern\",\n    width=1000,\n    rot=45,\n    title=title,\n    ylabel=\"Duration (s)\",\n    xlabel=\"Chunk Size, Query type\",\n)\n</pre> title = \"Duration to load data for difference access patterns\" plt = df.hvplot.bar(     x=\"chunk_size\",     y=\"mean_time\",     by=\"access_pattern\",     width=1000,     rot=45,     title=title,     ylabel=\"Duration (s)\",     xlabel=\"Chunk Size, Query type\", ) In\u00a0[9]: Copied! <pre>plt\n</pre> plt Out[9]: <p>Note how much longer it takes to query the dataset when the dataset is comprised of a single chunk, especially for small subsets of the data such as a time-series, spatial slice, or random point.</p>"},{"location":"massive-chunks/#massive-data-chunks","title":"Massive data chunks\u00b6","text":"<p>There are multiple reasons why you should avoid using too large of chunk sizes in your datacubes:</p> <ul> <li>In most cases, a chunk represents the minimum amount of data that needs to be fetched for any data operations. Consider a datacube with 1 GB chunks. An application or library would fetch the full GB even if a user wants to query only a single point represented by an 8 byte value. This leads to slowness as the user waits for the data to be fetched and decompressed and potentially costs if there is data egress.</li> <li>Many parallelization frameworks, such as Dask, operate on a chunk-by-chunk basis. Splitting your datacube over too few/large chunks means that you cannot effectively leverage parallel computations.</li> </ul>"},{"location":"massive-chunks/#demonstrating-performance-inefficiencies-of-too-large-of-chunks","title":"Demonstrating performance inefficiencies of too large of chunks\u00b6","text":""},{"location":"non-standardized-metadata/","title":"Non-standardized metadata","text":""},{"location":"non-standardized-metadata/#non-standardized-metadata","title":"Non-standardized metadata\u00b6","text":"<p>Data and metadata standardization is essential for interoperability. For example, following the climate and forecast (CF) conventions where applicable ensures people to use the data in a wide range of software libraries and applications including GDAL, Xarray, QGIS, ArcGIS, THREDDS, Iris, CGO, and Microsoft Planetary Computer Pro's tiling service.</p>"},{"location":"old-libraries/","title":"Using old libraries","text":"<p>Software libraries are constantly making bug fixes, performance improvements, and adding new features. By using old versions of libraries, you may be missing out on key improvements that could greatly increase your product. Most open source libraries maintain a changelog or release notes where you can review what's included in new releases. For example, check out Zarr's, Xarray's, and GDAL's.</p>"},{"location":"tiny-chunks/","title":"Tiny data chunks","text":"In\u00a0[1]: Copied! <pre>import datacube_benchmark\nimport zarr\nimport xarray as xr\nimport pandas as pd\nimport hvplot.pandas  # noqa\nfrom pint import Quantity\nfrom typing import Any\nfrom azure.identity import DefaultAzureCredential\nfrom obstore.auth.azure import AzureCredentialProvider\n</pre> import datacube_benchmark import zarr import xarray as xr import pandas as pd import hvplot.pandas  # noqa from pint import Quantity from typing import Any from azure.identity import DefaultAzureCredential from obstore.auth.azure import AzureCredentialProvider <p>Set constants to use when comparing datacubes</p> In\u00a0[2]: Copied! <pre>config = datacube_benchmark.Config\nconfig.target_array_size = \"1 GB\"\nconfig.credential_provider = AzureCredentialProvider(\n    credential=DefaultAzureCredential()\n)\nconfig.create_data = False\nconfig.warmup_samples = 1\n</pre> config = datacube_benchmark.Config config.target_array_size = \"1 GB\" config.credential_provider = AzureCredentialProvider(     credential=DefaultAzureCredential() ) config.create_data = False config.warmup_samples = 1 <p>Set the concurrency to use for the Zarr Python library</p> In\u00a0[3]: Copied! <pre>zarr.config.set({\"async.concurrency\": config.zarr_concurrency})\n</pre> zarr.config.set({\"async.concurrency\": config.zarr_concurrency}) Out[3]: <pre>&lt;donfig.config_obj.ConfigSet at 0x77eecb7f8550&gt;</pre> <p>Create (or reuse) a blosc compressed array with 25 KB chunks</p> In\u00a0[4]: Copied! <pre>url_for_tiny_chunks = (\n    \"https://datacubeguide.blob.core.windows.net/performance-testing/tiny-chunks.zarr\"\n)\ntiny_chunk_arr = datacube_benchmark.create_or_open_zarr_array(\n    url_for_tiny_chunks, target_chunk_size=\"25 kilobyte\", config=config\n)\n</pre> url_for_tiny_chunks = (     \"https://datacubeguide.blob.core.windows.net/performance-testing/tiny-chunks.zarr\" ) tiny_chunk_arr = datacube_benchmark.create_or_open_zarr_array(     url_for_tiny_chunks, target_chunk_size=\"25 kilobyte\", config=config ) <p>Create (or reuse) a blosc compressed array with 25 MB chunks</p> In\u00a0[5]: Copied! <pre>url_for_reg_chunks = (\n    \"https://datacubeguide.blob.core.windows.net/performance-testing/reg-chunks.zarr\"\n)\nreg_chunk_arr = datacube_benchmark.create_or_open_zarr_array(\n    url_for_reg_chunks, target_chunk_size=\"25 megabyte\", config=config\n)\n</pre> url_for_reg_chunks = (     \"https://datacubeguide.blob.core.windows.net/performance-testing/reg-chunks.zarr\" ) reg_chunk_arr = datacube_benchmark.create_or_open_zarr_array(     url_for_reg_chunks, target_chunk_size=\"25 megabyte\", config=config ) <p>Compare the storage size of the two arrays.</p> In\u00a0[6]: Copied! <pre>def storage_statistics(arr: zarr.Array) -&gt; dict[str:Any]:\n    storage_size = Quantity(\n        datacube_benchmark.utils.array_storage_size(arr), \"bytes\"\n    ).to(\"GB\")\n    compression_ratio = arr.nbytes / storage_size.to(\"bytes\").magnitude\n    return {\"storage_size\": storage_size, \"compression_ratio\": compression_ratio}\n</pre> def storage_statistics(arr: zarr.Array) -&gt; dict[str:Any]:     storage_size = Quantity(         datacube_benchmark.utils.array_storage_size(arr), \"bytes\"     ).to(\"GB\")     compression_ratio = arr.nbytes / storage_size.to(\"bytes\").magnitude     return {\"storage_size\": storage_size, \"compression_ratio\": compression_ratio} In\u00a0[7]: Copied! <pre>reg_chunk_storage_stats = storage_statistics(reg_chunk_arr)\ntiny_chunks_storage_stats = storage_statistics(tiny_chunk_arr)\n</pre> reg_chunk_storage_stats = storage_statistics(reg_chunk_arr) tiny_chunks_storage_stats = storage_statistics(tiny_chunk_arr) In\u00a0[8]: Copied! <pre>print(\"Storage size of a 10 GB array in object storage:\")\nprint(f\"\\t25 KB chunks: {tiny_chunks_storage_stats['storage_size']:.2f}\")\nprint(f\"\\t25 MB chunks: {reg_chunk_storage_stats['storage_size']:.2f}\")\nprint(\"Compression ratio of a 10 GB array in object storage:\")\nprint(f\"\\t25 KB chunks: {tiny_chunks_storage_stats['compression_ratio']:.1f}\")\nprint(f\"\\t25 MB chunks: {reg_chunk_storage_stats['compression_ratio']:.1f}\")\n</pre> print(\"Storage size of a 10 GB array in object storage:\") print(f\"\\t25 KB chunks: {tiny_chunks_storage_stats['storage_size']:.2f}\") print(f\"\\t25 MB chunks: {reg_chunk_storage_stats['storage_size']:.2f}\") print(\"Compression ratio of a 10 GB array in object storage:\") print(f\"\\t25 KB chunks: {tiny_chunks_storage_stats['compression_ratio']:.1f}\") print(f\"\\t25 MB chunks: {reg_chunk_storage_stats['compression_ratio']:.1f}\") <pre>Storage size of a 10 GB array in object storage:\n\t25 KB chunks: 0.05 gigabyte\n\t25 MB chunks: 0.02 gigabyte\nCompression ratio of a 10 GB array in object storage:\n\t25 KB chunks: 20.8\n\t25 MB chunks: 53.8\n</pre> <p>Notice the much better compression ratio for a datacube with 25 MB chunks relative to a datacube with 25 KB chunks.</p> <p>Test the time required to load a random point, a time series, or a spatial slice for the array.</p> In\u00a0[9]: Copied! <pre>tiny_chunks_results = datacube_benchmark.benchmark_access_patterns(\n    tiny_chunk_arr,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n).reset_index(drop=True)\nreg_chunks_results = datacube_benchmark.benchmark_access_patterns(\n    reg_chunk_arr,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n).reset_index(drop=True)\n</pre> tiny_chunks_results = datacube_benchmark.benchmark_access_patterns(     tiny_chunk_arr,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ).reset_index(drop=True) reg_chunks_results = datacube_benchmark.benchmark_access_patterns(     reg_chunk_arr,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ).reset_index(drop=True) In\u00a0[10]: Copied! <pre>df = pd.concat([tiny_chunks_results, reg_chunks_results])\ndf[\"access_pattern\"] = df[\"access_pattern\"].replace(\n    {\n        \"point\": \"Random point\",\n        \"time_series\": \"Time series\",\n        \"spatial_slice\": \"Spatial slice\",\n        \"full\": \"Full scan\",\n    }\n)\ndf[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1)\ndf[\"chunk_size\"] = df.apply(\n    lambda row: f\"{row['chunk_size'].to(\"MB\").magnitude:,.2f} (MB)\", axis=1\n)\ndf\n</pre> df = pd.concat([tiny_chunks_results, reg_chunks_results]) df[\"access_pattern\"] = df[\"access_pattern\"].replace(     {         \"point\": \"Random point\",         \"time_series\": \"Time series\",         \"spatial_slice\": \"Spatial slice\",         \"full\": \"Full scan\",     } ) df[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1) df[\"chunk_size\"] = df.apply(     lambda row: f\"{row['chunk_size'].to(\"MB\").magnitude:,.2f} (MB)\", axis=1 ) df Out[10]: mean_time median_time std_time min_time max_time total_samples access_pattern array_shape chunk_shape chunk_size nchunks shard_shape array_dtype array_size_memory array_size_storage array_compressors compression_ratio zarr_concurrency 0 0.006557 0.006557253000210039 second 0.0 second 0.006557253000210039 second 0.006557253000210039 second 1 Random point (965, 360, 720) (19, 19, 19) 0.03 (MB) 36822 None float32 1.000512 gigabyte 0.048189051000000004 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 20.76:1 128 1 0.036745 0.03674469600082375 second 0.0 second 0.03674469600082375 second 0.03674469600082375 second 1 Time series (965, 360, 720) (19, 19, 19) 0.03 (MB) 36822 None float32 1.000512 gigabyte 0.048189051000000004 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 20.76:1 128 2 0.391419 0.39141855200068676 second 0.0 second 0.39141855200068676 second 0.39141855200068676 second 1 Spatial slice (965, 360, 720) (19, 19, 19) 0.03 (MB) 36822 None float32 1.000512 gigabyte 0.048189051000000004 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 20.76:1 128 3 21.369652 21.369652307999786 second 0.0 second 21.369652307999786 second 21.369652307999786 second 1 Full scan (965, 360, 720) (19, 19, 19) 0.03 (MB) 36822 None float32 1.000512 gigabyte 0.048189051000000004 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 20.76:1 128 0 0.077645 0.07764525400125422 second 0.0 second 0.07764525400125422 second 0.07764525400125422 second 1 Random point (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 1 0.077246 0.07724585100004333 second 0.0 second 0.07724585100004333 second 0.07724585100004333 second 1 Time series (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 2 0.047293 0.04729349899935187 second 0.0 second 0.04729349899935187 second 0.04729349899935187 second 1 Spatial slice (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 3 0.663260 0.6632603899997775 second 0.0 second 0.6632603899997775 second 0.6632603899997775 second 1 Full scan (965, 360, 720) (185, 185, 185) 25.33 (MB) 48 None float32 1.000512 gigabyte 0.018597328 gigabyte (BloscCodec(typesize=4, cname=&lt;BloscCname.zstd... 53.80:1 128 In\u00a0[11]: Copied! <pre>title = \"Duration to load data for difference access patterns\"\nplt = df.hvplot.bar(\n    x=\"chunk_size\",\n    y=\"mean_time\",\n    by=\"access_pattern\",\n    width=1000,\n    rot=45,\n    title=title,\n    ylabel=\"Duration (s)\",\n    xlabel=\"Chunk Size, Query type\",\n)\n</pre> title = \"Duration to load data for difference access patterns\" plt = df.hvplot.bar(     x=\"chunk_size\",     y=\"mean_time\",     by=\"access_pattern\",     width=1000,     rot=45,     title=title,     ylabel=\"Duration (s)\",     xlabel=\"Chunk Size, Query type\", ) In\u00a0[12]: Copied! <pre>plt\n</pre> plt Out[12]: <p>Note that while random point access is faster for datacubes with smaller chunks, the time for loading many chunks is dramatically worse. This performance impact is even more noticeable for writing data.</p> In\u00a0[13]: Copied! <pre>def xarray_array_from_zarr_array(\n    array: zarr.Array, config=datacube_benchmark.Config\n) -&gt; xr.Dataset:\n    store = array.store\n    ds = xr.open_zarr(store=store, zarr_format=3, consolidated=True)\n    da = ds[config.data_var]\n    return da\n</pre> def xarray_array_from_zarr_array(     array: zarr.Array, config=datacube_benchmark.Config ) -&gt; xr.Dataset:     store = array.store     ds = xr.open_zarr(store=store, zarr_format=3, consolidated=True)     da = ds[config.data_var]     return da In\u00a0[14]: Copied! <pre>result_tiny_chunks = xarray_array_from_zarr_array(tiny_chunk_arr) * 3\nresult_tiny_chunks.data\n</pre> result_tiny_chunks = xarray_array_from_zarr_array(tiny_chunk_arr) * 3 result_tiny_chunks.data Out[14]:  Array   Chunk   Bytes   0.93 GiB   26.79 kiB   Shape   (965, 360, 720)   (19, 19, 19)   Dask graph   36822 chunks in 3 graph layers   Data type   float32 numpy.ndarray  720 360 965 In\u00a0[15]: Copied! <pre>result_reg_chunks = xarray_array_from_zarr_array(reg_chunk_arr) * 3\nresult_reg_chunks.data\n</pre> result_reg_chunks = xarray_array_from_zarr_array(reg_chunk_arr) * 3 result_reg_chunks.data Out[15]:  Array   Chunk   Bytes   0.93 GiB   24.15 MiB   Shape   (965, 360, 720)   (185, 185, 185)   Dask graph   48 chunks in 3 graph layers   Data type   float32 numpy.ndarray  720 360 965 <p>Note how many chunks Dask needs to track in the first dataset. This leads to Dask struggling because the task graph becomes too large with the overhead associated with each task becoming burdensome along with lots of extra network transfer between the client and worker nodes. This can be circumvented by using different Dask chunks than the chunks in storage, but most users do not configure this and will get frustrated with Dask struggling to perform computations on the data.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tiny-chunks/#tiny-data-chunks","title":"Tiny data chunks\u00b6","text":"<p>There are three primary reasons why you should avoid using too small of chunk sizes in your datacubes:</p> <ul> <li>Inefficient compression since most compression algorithms leverage correlations within a chunk.</li> <li>Inefficient data loading when querying large subsets of the data cube due to numerous GET requests with high latency. The excessive GET requests also increases costs.</li> <li>Inefficient encoding/decoding due to the number of chunks greatly exceeding available parallelism.</li> <li>Issues with parallel computing frameworks like Dask that have a 1:1 mapping between tasks and chunks.</li> </ul> <p>Please note that issue of too many GET requests can be mitigated by using Zarr V3 sharding or a cloud-native file format that allows storing multiple chunks in a single file.</p>"},{"location":"tiny-chunks/#demonstrating-storage-inefficiencies-of-too-small-of-chunks","title":"Demonstrating storage inefficiencies of too small of chunks\u00b6","text":""},{"location":"tiny-chunks/#demonstrating-performance-inefficiencies-of-too-small-of-chunks","title":"Demonstrating performance inefficiencies of too small of chunks\u00b6","text":""},{"location":"tiny-chunks/#demonstrating-dask-task-graph-issue-with-too-small-of-chunks","title":"Demonstrating Dask task graph issue with too small of chunks\u00b6","text":""},{"location":"tiny-coordinate-chunks/","title":"Tiny coordinate chunks","text":"In\u00a0[1]: Copied! <pre>import datacube_benchmark\nimport zarr\nimport pandas as pd\nimport hvplot.pandas  # noqa\nfrom azure.identity import DefaultAzureCredential\nfrom obstore.auth.azure import AzureCredentialProvider\n</pre> import datacube_benchmark import zarr import pandas as pd import hvplot.pandas  # noqa from azure.identity import DefaultAzureCredential from obstore.auth.azure import AzureCredentialProvider <p>Set constants to use when comparing datacubes</p> In\u00a0[2]: Copied! <pre>config = datacube_benchmark.Config\nconfig.target_array_size = \"1 GB\"\nconfig.credential_provider = AzureCredentialProvider(\n    credential=DefaultAzureCredential()\n)\nconfig.create_data = True\nconfig.warmup_samples = 1\n</pre> config = datacube_benchmark.Config config.target_array_size = \"1 GB\" config.credential_provider = AzureCredentialProvider(     credential=DefaultAzureCredential() ) config.create_data = True config.warmup_samples = 1 In\u00a0[3]: Copied! <pre>zarr.config.set({\"async.concurrency\": config.zarr_concurrency})\n</pre> zarr.config.set({\"async.concurrency\": config.zarr_concurrency}) Out[3]: <pre>&lt;donfig.config_obj.ConfigSet at 0x78ddcd55c2d0&gt;</pre> <p>Create (or reuse) a blosc compressed array with 25 MB chunks</p> In\u00a0[4]: Copied! <pre>url_for_unchunked_coords = \"https://datacubeguide.blob.core.windows.net/performance-testing/unchunked-coords.zarr\"\nunchunked_coords_store = datacube_benchmark.create_or_open_zarr_store(\n    url_for_unchunked_coords,\n    target_chunk_size=\"25 megabyte\",\n    config=config,\n    chunked_coords=False,\n)\n</pre> url_for_unchunked_coords = \"https://datacubeguide.blob.core.windows.net/performance-testing/unchunked-coords.zarr\" unchunked_coords_store = datacube_benchmark.create_or_open_zarr_store(     url_for_unchunked_coords,     target_chunk_size=\"25 megabyte\",     config=config,     chunked_coords=False, ) In\u00a0[5]: Copied! <pre>url_for_chunked_coords = \"https://datacubeguide.blob.core.windows.net/performance-testing/chunked-coords.zarr\"\nchunked_coords_store = datacube_benchmark.create_or_open_zarr_store(\n    url_for_chunked_coords,\n    target_chunk_size=\"25 megabyte\",\n    config=config,\n    chunked_coords=True,\n)\n</pre> url_for_chunked_coords = \"https://datacubeguide.blob.core.windows.net/performance-testing/chunked-coords.zarr\" chunked_coords_store = datacube_benchmark.create_or_open_zarr_store(     url_for_chunked_coords,     target_chunk_size=\"25 megabyte\",     config=config,     chunked_coords=True, ) <p>Test time required to open the Zarr store using Xarray</p> In\u00a0[6]: Copied! <pre>unchunked_coords_results = datacube_benchmark.benchmark_dataset_open(\n    unchunked_coords_store,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n)\nchunked_coords_results = datacube_benchmark.benchmark_dataset_open(\n    chunked_coords_store,\n    num_samples=config.num_samples,\n    warmup_samples=config.warmup_samples,\n)\n</pre> unchunked_coords_results = datacube_benchmark.benchmark_dataset_open(     unchunked_coords_store,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ) chunked_coords_results = datacube_benchmark.benchmark_dataset_open(     chunked_coords_store,     num_samples=config.num_samples,     warmup_samples=config.warmup_samples, ) In\u00a0[7]: Copied! <pre>df = pd.concat([chunked_coords_results.T, unchunked_coords_results.T])\ndf[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1)\ndf[\"zarr_store\"] = df[\"zarr_store\"].replace(\n    {\n        'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/chunked-coords.zarr\")': \"Chunked\",\n        'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/unchunked-coords.zarr\")': \"Unchunked\",\n    }\n)\n</pre> df = pd.concat([chunked_coords_results.T, unchunked_coords_results.T]) df[\"mean_time\"] = df.apply(lambda row: float(row[\"mean_time\"].magnitude), axis=1) df[\"zarr_store\"] = df[\"zarr_store\"].replace(     {         'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/chunked-coords.zarr\")': \"Chunked\",         'object_store://AzureStore(container_name=\"performance-testing\", account_name=\"datacubeguide\", prefix=\"performance-testing/unchunked-coords.zarr\")': \"Unchunked\",     } ) In\u00a0[8]: Copied! <pre>title = \"Duration to open dataset using Xarray\"\nplt = df.hvplot.bar(\n    x=\"zarr_store\",\n    y=\"mean_time\",\n    width=1000,\n    rot=45,\n    title=title,\n    ylabel=\"Duration (s)\",\n    xlabel=\"Coordinate chunking\",\n)\n</pre> title = \"Duration to open dataset using Xarray\" plt = df.hvplot.bar(     x=\"zarr_store\",     y=\"mean_time\",     width=1000,     rot=45,     title=title,     ylabel=\"Duration (s)\",     xlabel=\"Coordinate chunking\", ) In\u00a0[9]: Copied! <pre>plt\n</pre> plt Out[9]: <p>Note how much longer it takes to even open a dataset when the coordinates are split into many chunks.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tiny-coordinate-chunks/#tiny-coordinate-chunks","title":"Tiny coordinate chunks\u00b6","text":"<p>The reasons to avoid tiny coordinate chunks are the same as for avoiding tiny data chunks and are repeated below. It's worth mentioning separately though because many people produce datacubes by concatenating data split across many files. When using Xarray, the chunks in each individual file are propagated to the final datacube for the coordinates. For example, if you concatenate 365 data files each containing one time-step, your time coordinate would consist of 365 chunks each of length one, which would produce terrible performance.</p> <p>Reasons for avoiding tiny chunks:</p> <ul> <li>Inefficient compression since most compression algorithms leverage correlations within a chunk.</li> <li>Inefficient data loading when querying large subsets of the data cube due to numerous GET requests with high latency. The excessive GET requests also increases costs.</li> <li>Inefficient encoding/decoding due to the number of chunks greatly exceeding available parallelism.</li> <li>Issues with parallel computing frameworks like Dask that have a 1:1 mapping between tasks and chunks.</li> </ul> <p>Please note that issue of too many GET requests can be mitigated by using Zarr V3 sharding or a cloud-native file format that allows storing multiple chunks in a single file.</p>"},{"location":"tiny-coordinate-chunks/#demonstrating-inefficiencies-of-tiny-coordinate-chunks","title":"Demonstrating inefficiencies of tiny coordinate chunks\u00b6","text":""},{"location":"xarray-combine-defaults/","title":"Default Xarray combine parameters","text":"<p>Xarray's default combine operations  are overly permissive and can lead to unintuitive behavior and poor performance. Guidance for better arguments can be found in the xarray documentation and issue proposing stricter defaults, which is being addressed in an open pull request.</p>"},{"location":"datacube-benchmark/api/","title":"API Documentation","text":""},{"location":"datacube-benchmark/api/#datacube_benchmark.utils.array_storage_size","title":"datacube_benchmark.utils.array_storage_size","text":"<pre><code>array_storage_size(array: Array) -&gt; int\n</code></pre> <p>Calculate the total storage size of a Zarr array by summing the sizes of its chunks.</p>"},{"location":"datacube-benchmark/api/#datacube_benchmark.create_empty_dataarray","title":"datacube_benchmark.create_empty_dataarray","text":"<pre><code>create_empty_dataarray(\n    target_array_size: str | Quantity = \"1 GB\",\n    target_spatial_resolution: str | Quantity = \".5 degrees\",\n    target_chunk_size: str | Quantity = \"10 MB\",\n    target_chunk_shape: TARGET_SHAPES = \"dumpling\",\n    dtype: dtype = dtype(\"float32\"),\n) -&gt; DataArray\n</code></pre> <p>Create an empty xarray.DataArray with specified size, shape, and dtype.</p> <p>Parameters:</p> <ul> <li> <code>target_array_size</code>               (<code>str | Quantity</code>, default:                   <code>'1 GB'</code> )           \u2013            <p>The size of the xarray.DataArray, can be a string or a pint.Quantity. String must be convertible to a pint.Quantity.</p> </li> <li> <code>target_spatial_resolution</code>               (<code>str | Quantity</code>, default:                   <code>'.5 degrees'</code> )           \u2013            <p>The spatial resolution of the xarray.DataArray, can be a string or a pint.Quantity. String must be convertible to a pint.Quantity.</p> </li> <li> <code>target_chunk_size</code>               (<code>str | Quantity</code>, default:                   <code>'10 MB'</code> )           \u2013            <p>The size of the chunks in the xarray.DataArray, can be a string or a pint.Quantity. String must be convertible to a pint.Quantity.</p> </li> <li> <code>target_chunk_shape</code>               (<code>TARGET_SHAPES</code>, default:                   <code>'dumpling'</code> )           \u2013            <p>The shape of the xarray.DataArray, default is \"dumpling\".</p> </li> <li> <code>dtype</code>               (<code>dtype</code>, default:                   <code>dtype('float32')</code> )           \u2013            <p>The data type of the xarray.DataArray, default is np.dtype(\"float32\")</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataArray</code>           \u2013            <p>An empty xarray.DataArray with the specified parameters.</p> </li> </ul>"},{"location":"datacube-benchmark/api/#datacube_benchmark.create_zarr_store","title":"datacube_benchmark.create_zarr_store","text":"<pre><code>create_zarr_store(\n    object_store: ObjectStore,\n    target_array_size: str | Quantity = \"1 GB\",\n    target_spatial_resolution: str | Quantity = \".5 degrees\",\n    target_chunk_size: str | Quantity = \"10 MB\",\n    target_chunk_shape: TARGET_SHAPES = \"dumpling\",\n    compressor: Codec | BytesBytesCodec | None = None,\n    dtype: dtype = dtype(\"float32\"),\n    fill_method: Literal[\"random\", \"zeros\", \"ones\", \"arange\"] = \"arange\",\n    chunked_coords: bool = False,\n    consolidated_metadata: bool = True,\n) -&gt; ObjectStore\n</code></pre> <p>Create a Zarr store in the specified object store with an empty dataset.</p> <p>Parameters:</p> <ul> <li> <code>object_store</code>               (<code>ObjectStore</code>)           \u2013            <p>The object store to write the Zarr dataset to.</p> </li> <li> <code>target_array_size</code>               (<code>str | Quantity</code>, default:                   <code>'1 GB'</code> )           \u2013            <p>The size of the xarray.DataArray, can be a string or a pint.Quantity. String must be convertible to a pint.Quantity.</p> </li> <li> <code>target_spatial_resolution</code>               (<code>str | Quantity</code>, default:                   <code>'.5 degrees'</code> )           \u2013            <p>The spatial resolution of the xarray.DataArray, can be a string or a pint.Quantity. String must be convertible to a pint.Quantity.</p> </li> <li> <code>target_chunk_size</code>               (<code>str | Quantity</code>, default:                   <code>'10 MB'</code> )           \u2013            <p>The size of the chunks in the xarray.DataArray, can be a string or a pint.Quantity. String must be convertible to a pint.Quantity.</p> </li> <li> <code>target_chunk_shape</code>               (<code>TARGET_SHAPES</code>, default:                   <code>'dumpling'</code> )           \u2013            <p>The shape of the xarray.DataArray, default is \"dumpling\".</p> </li> <li> <code>compressor</code>               (<code>Codec | BytesBytesCodec | None</code>, default:                   <code>None</code> )           \u2013            <p>The compressor to use for the Zarr store, default is None (no compression).</p> </li> <li> <code>dtype</code>               (<code>dtype</code>, default:                   <code>dtype('float32')</code> )           \u2013            <p>The data type of the xarray.DataArray, default is np.dtype(\"float32\").</p> </li> <li> <code>fill_method</code>               (<code>Literal['random', 'zeros', 'ones', 'arange']</code>, default:                   <code>'arange'</code> )           \u2013            <p>The method to use for filling the Zarr array. Options are:</p> <ul> <li><code>\"random\"</code>: Fill with random values.</li> <li><code>\"zeros\"</code>: Fill with zeros.</li> <li><code>\"ones\"</code>: Fill with ones.</li> <li><code>\"arange\"</code>: Fill with a range of values.</li> </ul> </li> <li> <code>chunked_coords</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether coords are chunked or not. Chunk size would be (1,).</p> </li> <li> <code>consolidated_metadata</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to consolidate the Zarr metadata.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ObjectStore</code>           \u2013            <p>A Zarr store with the specified parameters.</p> </li> </ul>"},{"location":"datacube-benchmark/api/#datacube_benchmark.benchmark_zarr_array","title":"datacube_benchmark.benchmark_zarr_array","text":"<pre><code>benchmark_zarr_array(\n    zarr_array: Array,\n    access_pattern: Literal[\n        \"point\", \"time_series\", \"spatial_slice\", \"full\"\n    ] = \"point\",\n    num_samples: int = 10,\n    warmup_samples: int = 10,\n) -&gt; dict\n</code></pre> <p>Comprehensive benchmark of zarr array random access performance.</p> <p>Returns detailed statistics about the performance.</p> <p>Parameters:</p> <ul> <li> <code>zarr_array</code>               (<code>Array</code>)           \u2013            <p>The zarr array to benchmark</p> </li> <li> <code>access_pattern</code>               (<code>Literal['point', 'time_series', 'spatial_slice', 'full']</code>, default:                   <code>'point'</code> )           \u2013            <p>Type of access pattern: \"point\", \"time_series\", \"spatial_slice\", \"full\"</p> </li> <li> <code>num_samples</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Number of random access operations to perform</p> </li> <li> <code>warmup_samples</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Number of warmup operations (not included in timing)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>A dictionary containing performance statistics including mean, median, std deviation, min, max access times and details about the zarr array such as shape, dtype, and size.</p> </li> </ul>"},{"location":"datacube-benchmark/api/#datacube_benchmark.benchmark_access_patterns","title":"datacube_benchmark.benchmark_access_patterns","text":"<pre><code>benchmark_access_patterns(\n    zarr_array: Array, num_samples: int = 10, warmup_samples: int = 10\n) -&gt; DataFrame\n</code></pre> <p>Benchmark all three access patterns and return combined results.</p> <p>Parameters:</p> <ul> <li> <code>zarr_array</code>               (<code>Array</code>)           \u2013            <p>The zarr array to benchmark</p> </li> <li> <code>num_samples</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Number of random access operations to perform for each pattern</p> </li> <li> <code>warmup_samples</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Number of warmup operations (not included in timing)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pandas.DataFrame with results for each access pattern</p> </li> </ul>"},{"location":"datacube-benchmark/api/#datacube_benchmark.types.TARGET_SHAPES","title":"datacube_benchmark.types.TARGET_SHAPES  <code>module-attribute</code>","text":"<pre><code>TARGET_SHAPES = Literal['pancake', 'dumpling', 'churro']\n</code></pre>"}]}
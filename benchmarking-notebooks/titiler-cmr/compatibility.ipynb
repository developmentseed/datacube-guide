{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44dbc99",
   "metadata": {},
   "source": [
    "# Overview of compatibility testing\n",
    "\n",
    "This notebook walks you through a workflow to **check compatibility** of a [TiTiler-CMR](https://github.com/developmentseed/titiler-cmr) deployment for a given Earthdata CMR dataset.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "**üìö In this notebook, you'll learn**:\n",
    "\n",
    "1. Use `earthaccess` to authenticate to NASA Earthdata and query the CMR catalog\n",
    "2. Collect collection-level metadata (concept IDs, temporal range, spatial bounds)\n",
    "3. Run `check_titiler_cmr_compatibility` against your TiTiler-CMR endpoint to validate whether a dataset can be successfully visualized and accessed via TiTiler-CMR.\n",
    "\n",
    "\n",
    "Before you begin, you need:\n",
    "- An Earthdata login account: https://urs.earthdata.nasa.gov/\n",
    "- A valid `netrc` file with your Earthdata credentials or use interactive login.\n",
    "\n",
    "For this walkthrough, we will use the public instance hosted by [Open VEDA](https://staging.openveda.cloud/api/titiler-cmr/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a0edb6-7220-4910-854d-3b07d4e4f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import xarray as xr\n",
    "\n",
    "from datacube_benchmark.titiler import (\n",
    "    DatasetParams,\n",
    "    create_bbox_feature,\n",
    "    check_titiler_cmr_compatibility,\n",
    ")\n",
    "\n",
    "endpoint = \"https://staging.openveda.cloud/api/titiler-cmr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aab2bd",
   "metadata": {},
   "source": [
    "### Introduction to TiTiler-CMR\n",
    "[`Titiler-CMR`](https://github.com/developmentseed/titiler-cmr) is a dynamic map tile server that provides on-demand access to Earth science data managed by NASA's Common Metadata Repository (CMR). It allows users to dynamically generate and serve map tiles from multidimensional data formats like NetCDF and HDF5.\n",
    "\n",
    "To get started with TiTiler-CMR, you typically need to:\n",
    "- Choose a Titiler-CMR endpoint\n",
    "- Pick a CMR dataset (by concept ID)\n",
    "- Identify the assets/variables/bands you want to visualize\n",
    "- Define a temporal interval (`start/end` ISO range) and, if needed, a time step (e.g., daily).\n",
    "- Select a backend that matches your dataset‚Äôs structure\n",
    "\n",
    "`titiler-cmr` supports two different backends:\n",
    "  - **xarray** ‚Üí for gridded/cloud-native datasets (e.g., NetCDF4/HDF5), typically exposed as variables.\n",
    "  - **rasterio** ‚Üí for COG/raster imagery-style datasets exposed as bands (optionally via a regex).\n",
    "\n",
    "Here, we first explore a dataset using `earthaccess` to collect the necessary information such as **concept_id**, **backend**, and **variable**, then run a compatibility check using the `check_titiler_cmr_compatibility` helper function. If you already know your dataset, you can skip the exploration steps step 2 directly. \n",
    "\n",
    "## Step 1: Explore data with `earthaccess`\n",
    "You can use [`earthaccess`](https://github.com/nsidc/earthaccess) to search for dataset and inspect the individual granules used in your query. This helps you validate which files were accessed, their sizes, and the temporal range.\n",
    "\n",
    "First you need to authenticate to Earthdata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5712df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Earthdata\n",
    "try:\n",
    "    auth = earthaccess.login(strategy=\"environment\")\n",
    "except Exception:\n",
    "    auth = earthaccess.login(strategy=\"interactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972367c",
   "metadata": {},
   "source": [
    "Next, you can search for datasets using doi, keywords, temporal range, and spatial bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618eca85-a05c-4bfd-aa47-1576d9e932b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept-Id:  C1996881146-POCLOUD\n",
      "Abstract: A Group for High Resolution Sea Surface Temperature (GHRSST) Level 4 sea surface temperature analysis produced as a retrospective dataset (four day latency) and near-real-time dataset (one day latency) at the JPL Physical Oceanography DAAC using wavelets as basis functions in an optimal interpolation approach on a global 0.01 degree grid. The version 4 Multiscale Ultrahigh Resolution (MUR) L4 analysis is based upon nighttime GHRSST L2P skin and subskin SST observations from several instruments including the NASA Advanced Microwave Scanning Radiometer-EOS (AMSR-E), the JAXA Advanced Microwave Scanning Radiometer 2 on GCOM-W1, the Moderate Resolution Imaging Spectroradiometers (MODIS) on the NASA Aqua and Terra platforms, the US Navy microwave WindSat radiometer, the Advanced Very High Resolution Radiometer (AVHRR) on several NOAA satellites, and in situ SST observations from the NOAA iQuam project. The ice concentration data are from the archives at the EUMETSAT Ocean and Sea Ice Satellite Application Facility (OSI SAF) High Latitude Processing Center and are also used for an improved SST parameterization for the high-latitudes.  The dataset also contains additional variables for some granules including a SST anomaly derived from a MUR climatology and the temporal distance to the nearest IR measurement for each pixel.This dataset is funded by the NASA MEaSUREs program ( http://earthdata.nasa.gov/our-community/community-data-system-programs/measures-projects ), and created by a team led by Dr. Toshio M. Chin from JPL. It adheres to the GHRSST Data Processing Specification (GDS) version 2 format specifications. Use the file global metadata \"history:\" attribute to determine if a granule is near-realtime or retrospective.\n"
     ]
    }
   ],
   "source": [
    "datasets = earthaccess.search_datasets(doi=\"10.5067/GHGMR-4FJ04\")\n",
    "ds = datasets[0]\n",
    "\n",
    "concept_id = ds[\"meta\"][\"concept-id\"]\n",
    "print(\"Concept-Id: \", concept_id)\n",
    "print(\"Abstract:\", ds[\"umm\"][\"Abstract\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774cecbf-996b-4edf-8df2-a31d4422a6c3",
   "metadata": {},
   "source": [
    "### Examine the granules\n",
    "\n",
    "With a selected data collection, we'll now use `earthaccess.search_data` to find individual data granules within a specific temporal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1eecd4e-8ba0-4e67-b405-dbc7ae499b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 granules between 2024-10-12 and 2024-10-13\n",
      "\n",
      "2024-10-11T21:00:00.000Z ‚Üí 707.34 MB\n",
      "  https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20241012090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n"
     ]
    }
   ],
   "source": [
    "time_range = (\"2024-10-12\", \"2024-10-13\")\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    count=1,\n",
    "    concept_id=concept_id,\n",
    "    temporal=(\"2024-10-12\", \"2024-10-13\"),\n",
    ")\n",
    "print(f\"Found {len(results)} granules between {time_range[0]} and {time_range[1]}\")\n",
    "\n",
    "for g in results:\n",
    "    start = g[\"umm\"][\"TemporalExtent\"][\"RangeDateTime\"][\"BeginningDateTime\"]\n",
    "    size = float(g[\"size\"])  # or use g[\"granule_size_mb\"]\n",
    "\n",
    "    print(f\"\\n{start} ‚Üí {size:.2f} MB\")\n",
    "\n",
    "    for link in g.data_links(access=\"external\"):\n",
    "        print(\" \", link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e36c5f-9772-4cd5-a5bb-3fe443895e3a",
   "metadata": {},
   "source": [
    "From the output above, the returned link ends with `.nc`, indicating a **NetCDF** file. We can open it directly with **xarray** using the authenticated HTTPS session from `earthaccess` and quickly list the variables (plus a peek at dimensions and coordinates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "768c8f60-5f7b-40b3-a7ee-42c2b10361a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) float64 5GB ...\n",
       "    analysis_error    (time, lat, lon) float64 5GB ...\n",
       "    mask              (time, lat, lon) float32 3GB ...\n",
       "    sea_ice_fraction  (time, lat, lon) float64 5GB ...\n",
       "    dt_1km_data       (time, lat, lon) timedelta64[ns] 5GB ...\n",
       "    sst_anomaly       (time, lat, lon) float64 5GB ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = earthaccess.get_fsspec_https_session()\n",
    "\n",
    "ds = xr.open_dataset(\n",
    "    fs.open(results[0].data_links(access=\"external\")[0]),\n",
    "    engine=\"h5netcdf\",\n",
    "    decode_timedelta=True,\n",
    ")\n",
    "data_vars = ds.data_vars\n",
    "data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85292d1-4fff-4a41-b5ad-37f02e0d152a",
   "metadata": {},
   "source": [
    "\n",
    "Now, that we know the **concept_id**, **backend**, and **variable**, we can run a quick compatibility check using `check_titiler_cmr_compatibility()` helper function. \n",
    "\n",
    "## Step 2: Check Compatibility\n",
    "\n",
    "`check_titiler_cmr_compatibility()` helper function performs the following steps:\n",
    "- Validate the **CMR collection** and **granule search**\n",
    "- Resolve collection/granule metadata and fetch **TileJSON**\n",
    "- Determine how many **time steps** fall within the requested temporal range\n",
    "- Query the **`/timeseries/statistics`** endpoint for a small, bounded preview window to check if the dataset can be opened and processed with the selected backend.\n",
    "\n",
    "The result is a summary of compatibility, tiling parameters, and dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e41d95f-e087-4ee1-850a-5124710f7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_id = \"C2723754864-GES_DISC\"\n",
    "datetime_range = \"2024-10-12T00:00:01Z/2024-10-12T23:59:59Z\"\n",
    "variable = \"precipitation\"\n",
    "\n",
    "ds_xarray = DatasetParams(\n",
    "    concept_id=concept_id,\n",
    "    backend=\"xarray\",\n",
    "    datetime_range=datetime_range,\n",
    "    variable=variable,\n",
    "    step=\"P1D\",\n",
    "    temporal_mode=\"point\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b75cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TiTiler-CMR Compatibility Check ===\n",
      "Client: 8 physical / 8 logical cores | RAM: 16.00 GiB\n",
      "Dataset: C2723754864-GES_DISC (xarray)\n",
      "Found 1 timesteps/granules from TileJSON\n",
      "Using random bounds for compatibility check: [2.741770939582061, -86.93233148855214, 83.24021812957449, -46.68310789355593]\n",
      "Statistics returned 1 timesteps\n",
      "Compatibility: compatible\n"
     ]
    }
   ],
   "source": [
    "compat = await check_titiler_cmr_compatibility(\n",
    "    endpoint=endpoint,\n",
    "    dataset=ds_xarray,\n",
    "    timeout_s=250.0,\n",
    ")\n",
    "\n",
    "print(f\"Compatibility: {compat['compatibility']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a5f64",
   "metadata": {},
   "source": [
    "Now, we want to check the summary of data is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4f56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics preview:\n",
      "                       timestamp  min        max      mean         count  \\\n",
      "0  2024-10-12T00:00:00.000000000  0.0  36.904999  1.470654  324133.21875   \n",
      "\n",
      "            sum       std  median  majority  minority   unique  valid_percent  \\\n",
      "0  476687.84375  3.734399     0.0       0.0     0.065  14219.0          100.0   \n",
      "\n",
      "   masked_pixels  valid_pixels  percentile_2  percentile_98  \n",
      "0            0.0      325624.0           0.0      14.860001  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Statistics preview:\\n{compat['statistics']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11fa928-9db7-43e4-9642-7be44f1cbabc",
   "metadata": {},
   "source": [
    "### `rasterio` backend\n",
    "\n",
    "Similar to the `xarray` example above, we can check compatibility for a CMR collection that is better suited for the `rasterio` backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a85b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TiTiler-CMR Compatibility Check ===\n",
      "Client: 8 physical / 8 logical cores | RAM: 16.00 GiB\n",
      "Dataset: C2021957295-LPCLOUD (rasterio)\n",
      "Found 1 timesteps/granules from TileJSON\n",
      "Using random bounds for compatibility check: [-105.53889935418451, -46.63206063840639, -25.040452164192082, -6.3828370434101664]\n",
      "~~~~~~~~~~~~~~~~ ERROR JSON REQUEST ~~~~~~~~~~~~~~~~\n",
      "URL: https://staging.openveda.cloud/api/titiler-cmr/timeseries/statistics?concept_id=C2021957295-LPCLOUD&backend=rasterio&datetime=2024-07-01T00%3A00%3A00Z%2F2024-07-10T23%3A59%3A59Z&bands=B04&bands_regex=B%5B0-9%5D%5B0-9%5D&step=P1D&temporal_mode=point\n",
      "Error: 400 Bad Request\n",
      "Body: {\"detail\":\"The AOI for this request is too large for the /statistics endpoint for this dataset. Try again with either a smaller AOI\"}\n",
      "Statistics request failed: HTTPStatusError: Client error '400 Bad Request' for url 'https://staging.openveda.cloud/api/titiler-cmr/timeseries/statistics?concept_id=C2021957295-LPCLOUD&backend=rasterio&datetime=2024-07-01T00%3A00%3A00Z%2F2024-07-10T23%3A59%3A59Z&bands=B04&bands_regex=B%5B0-9%5D%5B0-9%5D&step=P1D&temporal_mode=point'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400\n",
      "Compatibility: issues_detected\n"
     ]
    }
   ],
   "source": [
    "ds_hls_day = DatasetParams(\n",
    "    concept_id=\"C2021957295-LPCLOUD\",\n",
    "    backend=\"rasterio\",\n",
    "    datetime_range=\"2024-07-01T00:00:00Z/2024-07-10T23:59:59Z\",\n",
    "    bands=[\"B05\", \"B04\"],\n",
    "    bands_regex=\"B[0-9][0-9]\",\n",
    "    step=\"P1D\",\n",
    "    temporal_mode=\"point\",\n",
    ")\n",
    "compat = await check_titiler_cmr_compatibility(\n",
    "    endpoint=endpoint,\n",
    "    dataset=ds_hls_day,\n",
    "    timeout_s=250.0,\n",
    ")\n",
    "\n",
    "print(f\"Compatibility: {compat['compatibility']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5664e",
   "metadata": {},
   "source": [
    "‚òùÔ∏è If your area of interest is too large, the API will return an ‚ÄúAOI is too large‚Äù error. Use the `create_bbox_feature` function to define a smaller bounding box before retrying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8ea321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TiTiler-CMR Compatibility Check ===\n",
      "Client: 8 physical / 8 logical cores | RAM: 16.00 GiB\n",
      "Dataset: C2021957295-LPCLOUD (rasterio)\n",
      "Found 1 timesteps/granules from TileJSON\n",
      "Statistics returned 0 timesteps\n",
      "Compatibility: compatible\n"
     ]
    }
   ],
   "source": [
    "gulf_geometry = create_bbox_feature(\n",
    "    -91.65432884883238, 47.86503396133904, -91.53842043960762, 47.9221313337365\n",
    ")\n",
    "compat = await check_titiler_cmr_compatibility(\n",
    "    endpoint=endpoint,\n",
    "    dataset=ds_hls_day,\n",
    "    geometry=gulf_geometry,\n",
    "    timeout_s=300.0,\n",
    ")\n",
    "print(f\"Compatibility: {compat['compatibility']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574d094",
   "metadata": {},
   "source": [
    "Alternatively, you can specify `bounds_fraction` to create a much smaller bounding box within the original bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d43515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TiTiler-CMR Compatibility Check ===\n",
      "Client: 8 physical / 8 logical cores | RAM: 16.00 GiB\n",
      "Dataset: C2021957295-LPCLOUD (rasterio)\n",
      "Found 1 timesteps/granules from TileJSON\n",
      "Using random bounds for compatibility check: [-129.466539636604, -10.179722642907745, -128.32811967894338, -9.610512664077437]\n",
      "Statistics returned 0 timesteps\n",
      "Compatibility: compatible\n"
     ]
    }
   ],
   "source": [
    "compat = await check_titiler_cmr_compatibility(\n",
    "    endpoint=endpoint,\n",
    "    dataset=ds_hls_day,\n",
    "    bounds_fraction=1e-5,\n",
    "    timeout_s=300.0,\n",
    ")\n",
    "print(f\"Compatibility: {compat['compatibility']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88c0ec-12e0-4583-a51d-b1be67d5e62b",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook demonstrated how to use `earthaccess` to explore CMR datasets and validate their compatibility with a TiTiler-CMR deployment using the `check_titiler_cmr_compatibility` helper function. \n",
    "\n",
    "\n",
    "### üìö Useful Resources\n",
    "- [Titiler-CMR GitHub](https://github.com/developmentseed/titiler-cmr)\n",
    "- [Earthaccess GitHub](https://github.com/nsidc/earthaccess)\n",
    "- [CMR Search](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacube-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
